/* SimpleApp, scala*/
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf

object SimpleApp {
  def main(args: Array[String]) {
    val logFile = "/user/spark/applicationHistory/textinput.txt" // Should be some file on your system
    val conf = new SparkConf().setAppName("Simple Application")
    val sc = new SparkContext(new SparkConf())
    //val sc = new SparkContext("local", "Simple", "/usr/local/spark-2.0.1-bin-hadoop2.7",List("target/scala-2.11/simple-project_2.11-1.0.jar"))

    //val logData = sc.textFile(logFile, 2).cache()
    //val numAs = logData.filter(line => line.contains("a")).count()
    //val numBs = logData.filter(line => line.contains("b")).count()
    //println("Lines with a: %s, Lines with b: %s".format(numAs, numBs))
    println("At At At end of the job")
  }
}

// /user/spark/applicationHistory
